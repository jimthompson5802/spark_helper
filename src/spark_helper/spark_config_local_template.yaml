# Spark Application Configuration Template for Local Spark
# This template provides common configuration parameters for Spark applications

# User-specific configurations
# Application information
appName: "SparkHelperApp"

# Local Spark Master 
# "local"	Run Spark locally with one worker thread (i.e. no parallelism at all).
# "local[K]"	Run Spark locally with K worker threads (ideally, set this to the number of cores on your machine).
# "local[K,F]"	Run Spark locally with K worker threads and F maxFailures (see spark.task.maxFailures for an explanation of this variable).
# "local[*]"	Run Spark locally with as many worker threads as logical cores on your machine.
# "local[*,F]"	Run Spark locally with as many worker threads as logical cores on your machine and F maxFailures.
# "local-cluster[N,C,M]"	Local-cluster mode is only for unit tests. It emulates a distributed cluster in a single JVM with N number of workers, C cores per worker and M MiB of memory per worker.

master: "local[*]"



